---
author: Danush Shekar
pubDatetime: 2021-01-01T19:00:00.000+05:30
modDatetime:
title: Fooling Automated Surveillance Cameras - Adversarial Patches to Attack Person Detection
featured: false
draft: false
slug: adversarial-patches
tags:
  - "2021"
  - Adversarial Attacks
  - Computer Vision
description: In this talk, we will discuss a paper about the generation of adversarial image patches that can be worn or held to be hidden from a person-detection classifier.
---

We have all seen machine learning algorithms gaining widespread attention in multiple industries. Surveillance and security is one such area where machine learning has applications in. Recent research papers have been focussing on finding image patches for such algorithms which cause say, a classifier, to ignore the said object. The arXiv paper I will be presenting is one such example, wherein the authors present an approach to generate adversarial image patches that one can wear or hold to be hidden from a person-detection classifier.

Additional resources:
- https://arxiv.org/abs/1904.08653
- https://arxiv.org/abs/1708.06131

<embed src="/labtalks/assets/slides/2021-01-01--Danush--adversarial-patches.pdf" type="application/pdf" width="100%" height="600px">
